{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "53d39c1552d645bb8f28ac1b127f3488b101b07d12440b10d5311af3d60aba01"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pytesseract import image_to_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "from config import CONFIG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "mytext = \"\"\"In the previous chapter, we saw examples of some common NLP \n",
    "applications that we might encounter in everyday life. If we were asked to \n",
    "build such an application, think about how we would approach doing so at our \n",
    "organization. We would normally walk through the requirements and break the \n",
    "problem down into several sub-problems, then try to develop a step-by-step \n",
    "procedure to solve them. Since language processing is involved, we would also\n",
    "list all the forms of text processing needed at each step. This step-by-step \n",
    "processing of text is known as pipeline. It is the series of steps involved in\n",
    "building any NLP model. These steps are common in every NLP project, so it \n",
    "makes sense to study them in this chapter. Understanding some common procedures\n",
    "in any NLP pipeline will enable us to get started on any NLP problem encountered \n",
    "in the workplace. Laying out and developing a text-processing pipeline is seen \n",
    "as a starting point for any NLP application development process. In this\n",
    "chapter, we will learn about the various steps involved and how they play  \n",
    "important roles in solving the NLP problem and we’ll see a few guidelines\n",
    "about when and how to use which step. In later chapters, we’ll discuss  \n",
    "specific pipelines for various NLP tasks (e.g., Chapters 4–7).\"\"\"\n",
    "\n",
    "my_sentences = sent_tokenize(mytext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['In the previous chapter, we saw examples of some common NLP \\napplications that we might encounter in everyday life.',\n",
       " 'If we were asked to \\nbuild such an application, think about how we would approach doing so at our \\norganization.',\n",
       " 'We would normally walk through the requirements and break the \\nproblem down into several sub-problems, then try to develop a step-by-step \\nprocedure to solve them.',\n",
       " 'Since language processing is involved, we would also\\nlist all the forms of text processing needed at each step.',\n",
       " 'This step-by-step \\nprocessing of text is known as pipeline.',\n",
       " 'It is the series of steps involved in\\nbuilding any NLP model.',\n",
       " 'These steps are common in every NLP project, so it \\nmakes sense to study them in this chapter.',\n",
       " 'Understanding some common procedures\\nin any NLP pipeline will enable us to get started on any NLP problem encountered \\nin the workplace.',\n",
       " 'Laying out and developing a text-processing pipeline is seen \\nas a starting point for any NLP application development process.',\n",
       " 'In this\\nchapter, we will learn about the various steps involved and how they play  \\nimportant roles in solving the NLP problem and we’ll see a few guidelines\\nabout when and how to use which step.',\n",
       " 'In later chapters, we’ll discuss  \\nspecific pipelines for various NLP tasks (e.g., Chapters 4–7).']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "my_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "def preprocess_corpus(texts):\n",
    "    mystopwords = set(stopwords.words(\"english\"))\n",
    "    def remove_stops_digits(tokens):\n",
    "        return [token.lower() for token in tokens if token not in mystopwords and not token.isdigit() and token not in punctuation]\n",
    "    return [remove_stops_digits(word_tokenize(text)) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = space.load(\"en_core_web_sm\")\n",
    "doc = nlp(u\"Charles Spencer Chapling was born on 16th April 1889 toHannah Chaplin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from config import CONFIG\n",
    "pretrainedPath = CONFIG.data / \"external\" / \"GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "w2v_model = KeyedVectors.load_word2vec_format(pretrainedPath, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9c978b7f2bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beautiful\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "w2v_model.most_similar([\"beautiful\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model."
   ]
  }
 ]
}